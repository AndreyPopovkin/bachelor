{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 9)\n",
    "\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe\n",
    "from tensorflow.python.eager.context import eager_mode, graph_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy snippet to reset the global graph and global session.\n",
    "with warnings.catch_warnings():\n",
    "  warnings.simplefilter('ignore')\n",
    "  tf.reset_default_graph()\n",
    "  try:\n",
    "    sess.close()\n",
    "  except:\n",
    "    pass\n",
    "  sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_alpha_transform = lambda y: np.log(y)  # Not using TF here.\n",
    "fwd_alpha_transform = tf.exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is model, where we should do binary classification - predict probability of A\n",
    "   1) num_classes - number of classes\n",
    "   2) each class has its popability of A\n",
    "   3) prob - array of these probabilities; they are Q - coordinates for Hamiltonian MCMC\n",
    "   4) prior (alpha, beta) are two float variables describing beta-distribution classes' popabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ps_prior(num_classes, dtype):\n",
    "    raw_prior_alpha = tf.get_variable(\n",
    "      name='raw_prior_alpha',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))\n",
    "    raw_prior_beta = tf.get_variable(\n",
    "      name='raw_prior_beta',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))   \n",
    "    return tfp.distributions.Independent(\n",
    "      tfp.distributions.Beta(\n",
    "          fwd_alpha_transform(raw_prior_alpha) * tf.ones(num_classes),\n",
    "          fwd_alpha_transform(raw_prior_beta) * tf.ones(num_classes)),\n",
    "      reinterpreted_batch_ndims=1)\n",
    "\n",
    "make_ps_prior = tf.make_template(name_='make_ps_prior', func_=_make_ps_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3_5 = tfp.distributions.Beta(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Beta/sample/Reshape:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta3_5.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3_5 = tfp.distributions.Beta([3,3],[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11668819, 0.47560385], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta3_5.sample()\n",
    "sess.run(beta3_5.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(5 * tf.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_betas = tfp.distributions.Independent(tfp.distributions.Beta(3 * tf.ones(2), 5 * tf.ones(2)),  reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34932178, 0.11226369], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(two_betas.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Binomial(\"Binomial/\", batch_shape=(3,), event_shape=(), dtype=float32)\n",
      "[0.36014998 0.34559998 0.9509907 ]\n"
     ]
    }
   ],
   "source": [
    "d = tfp.distributions.Binomial(total_count=[5.0,5.0,5.0], probs=[0.3,0.4,0.99])\n",
    "print(d)\n",
    "print(sess.run(d.prob([1,2,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Binomial(\"Binomial_1/\", batch_shape=(3,), event_shape=(), dtype=float32)\n",
      "-2.133959\n"
     ]
    }
   ],
   "source": [
    "d = tfp.distributions.Binomial(total_count=5.0, probs=[0.3,0.4,0.99])\n",
    "print(d)\n",
    "print(sess.run(tf.reduce_sum(d.log_prob([1,2,5]), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ps_log_likelihood(prob, class_id, total_count):\n",
    "  prob_c = tf.gather(prob, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "  total_count_c = tf.gather(total_count, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "  return tfp.distributions.Binomial(total_count=tf.to_float(total_count_c), probs=prob_c)\n",
    "\n",
    "make_ps_log_likelihood = tf.make_template(name_='make_ps_log_likelihood', func_=_make_ps_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-92074dddfb0d>:1: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[1.1 1.1 1.5 1.5 1.2 1.2 1.3 1.3 1.4 1.4]\n"
     ]
    }
   ],
   "source": [
    "res = tf.gather([0.1,0.2,0.3,0.4,0.5,0.6], indices=tf.to_int32([0,0,4,4,1,1,2,2,3,3]))\n",
    "print(sess.run(res)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_log_prob(prob, total_count, clicks, class_id, dtype):\n",
    "  num_classes = len(total_count)\n",
    "  rv_prob = make_ps_prior(num_classes, dtype)\n",
    "  rv_clicks = make_ps_log_likelihood(prob, class_id, total_count)\n",
    "  return (rv_prob.log_prob(prob) + \n",
    "         tf.reduce_sum(rv_clicks.log_prob(clicks), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_arr = np.array([\n",
    "    [20, 10, 1, 0.499993], [20, 3, 2, 0.230211], [20, 8, 3, 0.236831], \n",
    "    [20, 7, 4, 0.246463], [20, 6, 5, 0.370862], [20, 5, 6, 0.320656], \n",
    "    [20, 10, 7, 0.519887], [20, 12, 8, 0.52845], [20, 8, 9, 0.453077], \n",
    "    [20, 8, 10, 0.431245], [20, 10, 11, 0.499243], [20, 9, 12, 0.471968], \n",
    "    [20, 2, 13, 0.152176], [20, 14, 14, 0.48496], [20, 6, 15, 0.246193]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_count    float32\n",
       "clicks         float32\n",
       "class_id         int32\n",
       "true_p         float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_data_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>clicks</th>\n",
       "      <th>class_id</th>\n",
       "      <th>true_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.236831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.246463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.370862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.320656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.519887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.528450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.453077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.431245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.499243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.471968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.152176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.484960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.246193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_count  clicks  class_id    true_p\n",
       "1.0          20.0    10.0         1  0.499993\n",
       "2.0          20.0     3.0         2  0.230211\n",
       "3.0          20.0     8.0         3  0.236831\n",
       "4.0          20.0     7.0         4  0.246463\n",
       "5.0          20.0     6.0         5  0.370862\n",
       "6.0          20.0     5.0         6  0.320656\n",
       "7.0          20.0    10.0         7  0.519887\n",
       "8.0          20.0    12.0         8  0.528450\n",
       "9.0          20.0     8.0         9  0.453077\n",
       "10.0         20.0     8.0        10  0.431245\n",
       "11.0         20.0    10.0        11  0.499243\n",
       "12.0         20.0     9.0        12  0.471968\n",
       "13.0         20.0     2.0        13  0.152176\n",
       "14.0         20.0    14.0        14  0.484960\n",
       "15.0         20.0     6.0        15  0.246193"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_data_pd.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify unnormalized posterior.\n",
    "\n",
    "dtype = np.float32\n",
    "\n",
    "\n",
    "def unnormalized_posterior_log_prob(prob):\n",
    "  return joint_log_prob(\n",
    "      prob=prob,\n",
    "      total_count=dtype(ps_data_pd.total_count.values),\n",
    "      clicks=dtype(ps_data_pd.clicks.values),\n",
    "      class_id=np.int32(ps_data_pd.class_id.values),\n",
    "      dtype=dtype)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up E-step.\n",
    "'''\n",
    "def get_step_size():\n",
    "    with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
    "        tf.get_variable(\n",
    "            'step_size',\n",
    "            initializer=np.array(0.2, dtype=dtype),\n",
    "            trainable=False)\n",
    "\n",
    "step_size = get_step_size()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aapopovkin/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Set-up E-step.\n",
    "step_size = tf.get_variable(\n",
    "            'step_size',\n",
    "            initializer=np.array(0.2, dtype=dtype),\n",
    "            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-40b93817e4ac>:4: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "    num_leapfrog_steps=50,\n",
    "    step_size=0.01,\n",
    "    #step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(\n",
    "    #  num_adaptation_steps=None),\n",
    "    state_gradients_are_stopped=True)\n",
    "\n",
    "init_random_weights = tf.placeholder(dtype, shape=[len(ps_data_pd)])\n",
    "\n",
    "posterior_random_weights, kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=3,\n",
    "    num_burnin_steps=0,\n",
    "    num_steps_between_results=0,\n",
    "    current_state=init_random_weights,\n",
    "    kernel=hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up M-step.\n",
    "\n",
    "loss = -tf.reduce_mean(kernel_results.accepted_results.target_log_prob)\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate=0.1,\n",
    "    global_step=global_step,\n",
    "    decay_steps=2,\n",
    "    decay_rate=0.99)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aapopovkin/venv/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Initialize all variables.\n",
    "\n",
    "init_op = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab variable handles for diagnostic purposes.\n",
    "\n",
    "with tf.variable_scope('make_ps_prior', reuse=True):\n",
    "  prior_alpha = fwd_alpha_transform(tf.get_variable(\n",
    "      name='raw_prior_alpha', dtype=dtype))\n",
    "  prior_beta = fwd_alpha_transform(tf.get_variable(\n",
    "      name='raw_prior_beta', dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op.run()\n",
    "w_ = 0.5 * np.ones([len(ps_data_pd)], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.4f}\".format(sess.run(prior_beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior_beta = tf.tensor(5, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step:   1  loss:   30.4  acceptance:1.0000  step_size:0.20  prior_alpha:5.0000  prior_beta:5.0000\n",
      "global_step: 101  loss:   20.2  acceptance:0.9868  step_size:0.20  prior_alpha:4.2984  prior_beta:7.1030\n",
      "global_step: 201  loss:   22.0  acceptance:0.9917  step_size:0.20  prior_alpha:5.2532  prior_beta:7.4435\n",
      "global_step: 301  loss:   18.4  acceptance:0.9934  step_size:0.20  prior_alpha:6.5875  prior_beta:9.0078\n",
      "global_step: 401  loss:   23.4  acceptance:0.9942  step_size:0.20  prior_alpha:5.9255  prior_beta:10.3730\n",
      "global_step: 501  loss:   21.0  acceptance:0.9953  step_size:0.20  prior_alpha:6.9210  prior_beta:10.2164\n",
      "global_step: 601  loss:   20.8  acceptance:0.9961  step_size:0.20  prior_alpha:7.0446  prior_beta:10.2161\n",
      "global_step: 701  loss:   19.6  acceptance:0.9962  step_size:0.20  prior_alpha:6.8910  prior_beta:10.6410\n",
      "global_step: 801  loss:   19.5  acceptance:0.9967  step_size:0.20  prior_alpha:7.2718  prior_beta:10.8492\n",
      "global_step: 901  loss:   20.3  acceptance:0.9967  step_size:0.20  prior_alpha:7.3099  prior_beta:10.7852\n",
      "global_step:1001  loss:   16.8  acceptance:0.9967  step_size:0.20  prior_alpha:7.1300  prior_beta:11.2217\n",
      "global_step:1101  loss:   21.7  acceptance:0.9967  step_size:0.20  prior_alpha:7.0567  prior_beta:11.4064\n",
      "global_step:1201  loss:   18.8  acceptance:0.9967  step_size:0.20  prior_alpha:7.1770  prior_beta:11.1345\n",
      "global_step:1301  loss:   21.3  acceptance:0.9967  step_size:0.20  prior_alpha:7.2118  prior_beta:11.0384\n",
      "global_step:1401  loss:   22.9  acceptance:0.9969  step_size:0.20  prior_alpha:7.2035  prior_beta:11.0399\n",
      "global_step:1501  loss:   20.1  acceptance:0.9969  step_size:0.20  prior_alpha:7.2078  prior_beta:11.0119\n",
      "global_step:1601  loss:   24.5  acceptance:0.9971  step_size:0.20  prior_alpha:7.2169  prior_beta:11.0037\n",
      "global_step:1701  loss:   23.6  acceptance:0.9971  step_size:0.20  prior_alpha:7.2138  prior_beta:10.9945\n",
      "global_step:1801  loss:   19.2  acceptance:0.9965  step_size:0.20  prior_alpha:7.2111  prior_beta:10.9970\n",
      "global_step:1901  loss:   20.4  acceptance:0.9963  step_size:0.20  prior_alpha:7.2181  prior_beta:10.9848\n",
      "global_step:2001  loss:   18.2  acceptance:0.9963  step_size:0.20  prior_alpha:7.2157  prior_beta:10.9873\n",
      "global_step:2101  loss:   23.0  acceptance:0.9960  step_size:0.20  prior_alpha:7.2156  prior_beta:10.9877\n",
      "global_step:2201  loss:   25.3  acceptance:0.9961  step_size:0.20  prior_alpha:7.2166  prior_beta:10.9860\n",
      "global_step:2301  loss:   19.9  acceptance:0.9961  step_size:0.20  prior_alpha:7.2165  prior_beta:10.9862\n",
      "global_step:2401  loss:   20.7  acceptance:0.9963  step_size:0.20  prior_alpha:7.2159  prior_beta:10.9870\n",
      "global_step:2501  loss:   20.5  acceptance:0.9964  step_size:0.20  prior_alpha:7.2160  prior_beta:10.9868\n",
      "global_step:2601  loss:   22.1  acceptance:0.9964  step_size:0.20  prior_alpha:7.2160  prior_beta:10.9869\n",
      "global_step:2701  loss:   20.4  acceptance:0.9964  step_size:0.20  prior_alpha:7.2160  prior_beta:10.9868\n",
      "global_step:2801  loss:   18.7  acceptance:0.9965  step_size:0.20  prior_alpha:7.2159  prior_beta:10.9869\n",
      "global_step:2901  loss:   22.8  acceptance:0.9967  step_size:0.20  prior_alpha:7.2159  prior_beta:10.9869\n",
      "global_step:3000  loss:   26.8  acceptance:0.9963  step_size:0.20  prior_alpha:7.2159  prior_beta:10.9869\n"
     ]
    }
   ],
   "source": [
    "maxiter = int(3000)\n",
    "num_accepted = 0\n",
    "num_drawn = 0\n",
    "for i in range(maxiter):\n",
    "  [\n",
    "      _,\n",
    "      global_step_,\n",
    "      loss_,\n",
    "      posterior_random_weights_,\n",
    "      kernel_results_,\n",
    "      step_size_,\n",
    "      prior_alpha_,\n",
    "      prior_beta_\n",
    "  ] = sess.run([\n",
    "      train_op,\n",
    "      global_step,\n",
    "      loss,\n",
    "      posterior_random_weights,\n",
    "      kernel_results,\n",
    "      step_size,\n",
    "      prior_alpha,\n",
    "      prior_beta\n",
    "  ], feed_dict={init_random_weights: w_})\n",
    "  w_ = posterior_random_weights_[-1, :]\n",
    "  num_accepted += kernel_results_.is_accepted.sum()\n",
    "  num_drawn += kernel_results_.is_accepted.size\n",
    "  acceptance_rate = num_accepted / num_drawn\n",
    "  if i % 100 == 0 or i == maxiter - 1:\n",
    "    print('global_step:{:>4}  loss:{: 7.1f}  acceptance:{:.4f}  '\n",
    "          'step_size:{:.2f}  prior_alpha:{:.4f}  prior_beta:{:.4f}'.format(\n",
    "              global_step_, loss_.mean(),\n",
    "              acceptance_rate, step_size_,\n",
    "              prior_alpha_, prior_beta_)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.8840, 10.6375\n",
    "\n",
    "# 7.2159, 10.9869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
