{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 9)\n",
    "\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe\n",
    "from tensorflow.python.eager.context import eager_mode, graph_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy snippet to reset the global graph and global session.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    tf.reset_default_graph()\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    #sess = tf_debug.LocalCLIDebugWrapperSession(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_alpha_transform = lambda y: np.log(y)  # Not using TF here.\n",
    "fwd_alpha_transform = tf.exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is model, where we should do binary classification - predict probability of A\n",
    "   1) num_classes - number of classes\n",
    "   2) each class has its popability of A\n",
    "   3) prob - array of these probabilities; they are Q - coordinates for Hamiltonian MCMC\n",
    "   4) prior (alpha, beta) are two float variables describing beta-distribution classes' popabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ps_prior(num_classes, dtype):\n",
    "    raw_prior_alpha = tf.get_variable(\n",
    "      name='raw_prior_alpha',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))\n",
    "    raw_prior_beta = tf.get_variable(\n",
    "      name='raw_prior_beta',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))   \n",
    "    return tfp.distributions.Independent(\n",
    "      tfp.distributions.Beta(\n",
    "          fwd_alpha_transform(raw_prior_alpha) * tf.ones(num_classes),\n",
    "          fwd_alpha_transform(raw_prior_beta) * tf.ones(num_classes)),\n",
    "      reinterpreted_batch_ndims=1)\n",
    "\n",
    "make_ps_prior = tf.make_template(name_='make_ps_prior', func_=_make_ps_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3_5 = tfp.distributions.Beta(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Beta/sample/Reshape:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta3_5.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3_5 = tfp.distributions.Beta([3,3],[5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33741772, 0.34241349], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta3_5.sample()\n",
    "sess.run(beta3_5.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(5 * tf.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_betas = tfp.distributions.Independent(tfp.distributions.Beta(3 * tf.ones(2), 5 * tf.ones(2)),  reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5657742 , 0.52742934], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(two_betas.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Binomial(\"Binomial/\", batch_shape=(3,), event_shape=(), dtype=float32)\n",
      "[0.36014998 0.34559998 0.9509907 ]\n"
     ]
    }
   ],
   "source": [
    "d = tfp.distributions.Binomial(total_count=[5.0,5.0,5.0], probs=[0.3,0.4,0.99])\n",
    "print(d)\n",
    "print(sess.run(d.prob([1,2,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Binomial(\"Binomial_1/\", batch_shape=(3,), event_shape=(), dtype=float32)\n",
      "-2.133959\n"
     ]
    }
   ],
   "source": [
    "d = tfp.distributions.Binomial(total_count=5.0, probs=[0.3,0.4,0.99])\n",
    "print(d)\n",
    "print(sess.run(tf.reduce_sum(d.log_prob([1,2,5]), axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_ps_log_likelihood(prob, class_id, total_count):\n",
    "    prob_c = tf.gather(prob, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "    total_count_c = tf.gather(total_count, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "    return tfp.distributions.Binomial(total_count=tf.to_float(total_count_c), probs=prob_c)\n",
    "\n",
    "make_ps_log_likelihood = tf.make_template(name_='make_ps_log_likelihood', func_=_make_ps_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-92074dddfb0d>:1: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[1.1 1.1 1.5 1.5 1.2 1.2 1.3 1.3 1.4 1.4]\n"
     ]
    }
   ],
   "source": [
    "res = tf.gather([0.1,0.2,0.3,0.4,0.5,0.6], indices=tf.to_int32([0,0,4,4,1,1,2,2,3,3]))\n",
    "print(sess.run(res)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_log_prob(prob, total_count, clicks, class_id, dtype):\n",
    "    num_classes = len(total_count)\n",
    "    rv_prob = make_ps_prior(num_classes, dtype)\n",
    "    rv_clicks = make_ps_log_likelihood(prob, class_id, total_count)\n",
    "    return (rv_prob.log_prob(prob) + \n",
    "        tf.reduce_sum(rv_clicks.log_prob(clicks), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_arr = np.array([\n",
    "    [20, 10, 1, 0.499993], [20, 3, 2, 0.230211], [20, 8, 3, 0.236831], \n",
    "    [20, 7, 4, 0.246463], [20, 6, 5, 0.370862], [20, 5, 6, 0.320656], \n",
    "    [20, 10, 7, 0.519887], [20, 12, 8, 0.52845], [20, 8, 9, 0.453077], \n",
    "    [20, 8, 10, 0.431245], [20, 10, 11, 0.499243], [20, 9, 12, 0.471968], \n",
    "    [20, 2, 13, 0.152176], [20, 14, 14, 0.48496], [20, 6, 15, 0.246193]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_count    float32\n",
       "clicks         float32\n",
       "class_id         int32\n",
       "true_p         float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_data_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>clicks</th>\n",
       "      <th>class_id</th>\n",
       "      <th>true_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.236831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.246463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.370862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.320656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.519887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.528450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.453077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.431245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.499243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.471968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.152176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.484960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.246193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_count  clicks  class_id    true_p\n",
       "1.0          20.0    10.0         1  0.499993\n",
       "2.0          20.0     3.0         2  0.230211\n",
       "3.0          20.0     8.0         3  0.236831\n",
       "4.0          20.0     7.0         4  0.246463\n",
       "5.0          20.0     6.0         5  0.370862\n",
       "6.0          20.0     5.0         6  0.320656\n",
       "7.0          20.0    10.0         7  0.519887\n",
       "8.0          20.0    12.0         8  0.528450\n",
       "9.0          20.0     8.0         9  0.453077\n",
       "10.0         20.0     8.0        10  0.431245\n",
       "11.0         20.0    10.0        11  0.499243\n",
       "12.0         20.0     9.0        12  0.471968\n",
       "13.0         20.0     2.0        13  0.152176\n",
       "14.0         20.0    14.0        14  0.484960\n",
       "15.0         20.0     6.0        15  0.246193"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_data_pd.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify unnormalized posterior.\n",
    "\n",
    "dtype = np.float32\n",
    "\n",
    "\n",
    "def unnormalized_posterior_log_prob(prob):\n",
    "    return joint_log_prob(\n",
    "        prob=prob,\n",
    "        total_count=dtype(ps_data_pd.total_count.values),\n",
    "        clicks=dtype(ps_data_pd.clicks.values),\n",
    "        class_id=np.int32(ps_data_pd.class_id.values),\n",
    "        dtype=dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up E-step.\n",
    "'''\n",
    "def get_step_size():\n",
    "    with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
    "        tf.get_variable(\n",
    "            'step_size',\n",
    "            initializer=np.array(0.2, dtype=dtype),\n",
    "            trainable=False)\n",
    "\n",
    "step_size = get_step_size()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aapopovkin/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Set-up E-step.\n",
    "step_size = tf.get_variable(\n",
    "            'step_size',\n",
    "            initializer=np.array(0.1, dtype=dtype),\n",
    "            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "    num_leapfrog_steps=10,\n",
    "    step_size=0.01,#step_size,\n",
    "    #step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(\n",
    "    #  num_adaptation_steps=None),\n",
    "    state_gradients_are_stopped=True)\n",
    "\n",
    "init_random_weights = tf.placeholder(dtype, shape=[len(ps_data_pd)])\n",
    "\n",
    "posterior_random_weights, kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=3,\n",
    "    num_burnin_steps=0,\n",
    "    num_steps_between_results=0,\n",
    "    current_state=init_random_weights,\n",
    "    kernel=hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all variables.\n",
    "\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op.run()\n",
    "w_ = np.random.beta(1, 2, size=len(ps_data_pd)).astype(dtype)# 0.5 * np.ones([len(ps_data_pd)], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetropolisHastingsKernelResults(accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([-95.56643  ,  -2.0686707,   4.724431 ], dtype=float32), target_log_prob=array([-26.601244, -24.530464, -29.267681], dtype=float32), grads_target_log_prob=[array([[-15.197369 ,   7.0576315,  -4.719725 ,   2.2450454, -11.223586 ,\n",
      "          9.550534 , -14.106207 ,   0.8620472,  19.21813  , -24.370537 ,\n",
      "        -15.544897 ,  -6.2250757,  -1.3335171,   7.8560624,   7.7854166],\n",
      "       [ -9.514488 ,  29.795773 ,   6.4243174,  10.657215 ,  -9.106619 ,\n",
      "         -8.541821 , -10.163707 , -10.200941 ,  13.774683 ,  -2.9328756,\n",
      "        -13.30499  ,  -5.376053 ,  15.151863 ,  -1.8187151,   1.2874784],\n",
      "       [-21.663862 ,   1.1247444,  -1.1662779,   8.142054 ,  11.235966 ,\n",
      "        -11.999753 ,   1.2397634, -13.92033  ,  10.121515 ,  -9.391367 ,\n",
      "        -36.74359  ,  -3.6788948,  -4.3266897,  19.055866 ,  12.37598  ]],\n",
      "      dtype=float32)]), is_accepted=array([ True,  True,  True]), log_accept_ratio=array([ 1.0947647 ,  0.00210905, -0.01278591], dtype=float32), proposed_state=array([[0.62694424, 0.20841576, 0.4705658 , 0.37408334, 0.45659837,\n",
      "        0.25639707, 0.61883396, 0.56385726, 0.28786743, 0.6311864 ,\n",
      "        0.62948537, 0.51977974, 0.22252531, 0.574261  , 0.29887745],\n",
      "       [0.58263063, 0.12980218, 0.3748075 , 0.31126174, 0.43716794,\n",
      "        0.39428553, 0.5879402 , 0.6538815 , 0.3212941 , 0.4545414 ,\n",
      "        0.61275345, 0.51225734, 0.146589  , 0.6574847 , 0.34672773],\n",
      "       [0.67084444, 0.24261867, 0.43882877, 0.32869366, 0.27681103,\n",
      "        0.42623746, 0.48893613, 0.67966866, 0.34669632, 0.5123716 ,\n",
      "        0.7476109 , 0.49713188, 0.2426857 , 0.47320414, 0.2700206 ]],\n",
      "      dtype=float32), proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([-95.56643  ,  -2.0686707,   4.724431 ], dtype=float32), target_log_prob=array([-26.601244, -24.530464, -29.267681], dtype=float32), grads_target_log_prob=[array([[-15.197369 ,   7.0576315,  -4.719725 ,   2.2450454, -11.223586 ,\n",
      "          9.550534 , -14.106207 ,   0.8620472,  19.21813  , -24.370537 ,\n",
      "        -15.544897 ,  -6.2250757,  -1.3335171,   7.8560624,   7.7854166],\n",
      "       [ -9.514488 ,  29.795773 ,   6.4243174,  10.657215 ,  -9.106619 ,\n",
      "         -8.541821 , -10.163707 , -10.200941 ,  13.774683 ,  -2.9328756,\n",
      "        -13.30499  ,  -5.376053 ,  15.151863 ,  -1.8187151,   1.2874784],\n",
      "       [-21.663862 ,   1.1247444,  -1.1662779,   8.142054 ,  11.235966 ,\n",
      "        -11.999753 ,   1.2397634, -13.92033  ,  10.121515 ,  -9.391367 ,\n",
      "        -36.74359  ,  -3.6788948,  -4.3266897,  19.055866 ,  12.37598  ]],\n",
      "      dtype=float32)]), extra=[])]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([\n",
    "    kernel_results,\n",
    "    #posterior_random_weights,\n",
    "    #loss,\n",
    "    #train_op\n",
    "], feed_dict={init_random_weights: w_}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable make_ps_prior/raw_prior_alpha/Adam/ already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-28-b77bf5c240ab>\", line 14, in <module>\n    train_op = optimizer.minimize(loss, global_step=global_step)\n  File \"/home/aapopovkin/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/aapopovkin/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-b77bf5c240ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0;32m--> 413\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m   def compute_gradients(self, loss, var_list=None,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    593\u001b[0m                        ([str(v) for _, v, _ in converted_grads_and_vars],))\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/adam.py\u001b[0m in \u001b[0;36m_create_slots\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# Create slots for the first and second moments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"v\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36m_zeros_slot\u001b[0;34m(self, var, slot_name, op_name)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0mnamed_slots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamed_slots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m       \u001b[0mnew_slot_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m       self._restore_slot_variable(\n\u001b[1;32m   1155\u001b[0m           \u001b[0mslot_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36mcreate_zeros_slot\u001b[0;34m(primary, name, dtype, colocate_with_primary)\u001b[0m\n\u001b[1;32m    181\u001b[0m     return create_slot_with_initializer(\n\u001b[1;32m    182\u001b[0m         \u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         colocate_with_primary=colocate_with_primary)\n\u001b[0m\u001b[1;32m    184\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36mcreate_slot_with_initializer\u001b[0;34m(primary, initializer, shape, dtype, name, colocate_with_primary)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_vars_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n\u001b[0;32m--> 157\u001b[0;31m                                 dtype)\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36m_create_slot_var\u001b[0;34m(primary, val, scope, validate_shape, shape, dtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_resource_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_partitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_partitioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" % (err_msg, \"\".join(\n\u001b[0;32m--> 848\u001b[0;31m             traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable make_ps_prior/raw_prior_alpha/Adam/ already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-28-b77bf5c240ab>\", line 14, in <module>\n    train_op = optimizer.minimize(loss, global_step=global_step)\n  File \"/home/aapopovkin/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/aapopovkin/venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "# Set-up M-step.\n",
    "\n",
    "loss = -tf.reduce_mean(kernel_results.accepted_results.target_log_prob)\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    learning_rate=0.1,\n",
    "    global_step=global_step,\n",
    "    decay_steps=2,\n",
    "    decay_rate=0.99)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab variable handles for diagnostic purposes.\n",
    "\n",
    "with tf.variable_scope('make_ps_prior', reuse=True):\n",
    "    prior_alpha = fwd_alpha_transform(tf.get_variable(\n",
    "        name='raw_prior_alpha', dtype=dtype))\n",
    "    prior_beta = fwd_alpha_transform(tf.get_variable(\n",
    "        name='raw_prior_beta', dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.4f}\".format(sess.run(prior_beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-148.47824]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([\n",
    "    unnormalized_posterior_log_prob(w_),\n",
    "], feed_dict={init_random_weights: w_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step:   1  loss:      nan  acceptance:0.0000  step_size:0.1941  prior_alpha:nan  prior_beta:nan\n"
     ]
    }
   ],
   "source": [
    "maxiter = int(50)\n",
    "num_accepted = 0\n",
    "num_drawn = 0\n",
    "for i in range(1):\n",
    "    posterior_random_weights_,\n",
    "    kernel_results_,\n",
    "    loss_,\n",
    "    train_or = sess.run([\n",
    "        kernel_results,\n",
    "        posterior_random_weights,\n",
    "        loss,\n",
    "        train_op\n",
    "    ], feed_dict={init_random_weights: w_})\n",
    "    \n",
    "    global_step_ = sess.run(global_step)\n",
    "    step_size_ = sess.run(step_size)\n",
    "    prior_alpha_ = sess.run(prior_alpha)\n",
    "    prior_beta_ = sess.run(prior_beta)\n",
    "    \n",
    "    w_ = posterior_random_weights_[-1, :]\n",
    "    num_accepted += kernel_results_.is_accepted.sum()\n",
    "    num_drawn += kernel_results_.is_accepted.size\n",
    "    acceptance_rate = num_accepted / num_drawn\n",
    "    if i % 1 == 0 or i == maxiter - 1:\n",
    "        print('global_step:{:>4}  loss:{: 9.3f}  acceptance:{:.4f}  '\n",
    "              'step_size:{:.4f}  prior_alpha:{:.4f}  prior_beta:{:.4f}'.format(\n",
    "                  global_step_, loss_.mean(),\n",
    "                  acceptance_rate, step_size_,\n",
    "                  prior_alpha_, prior_beta_)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
