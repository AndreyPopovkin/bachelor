{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is model, where we should do binary classification - predict probability of A\n",
    "\n",
    "   1) num_classes - number of classes\n",
    "   \n",
    "   2) each class has its popability of A\n",
    "   \n",
    "   3) prob - array of these probabilities; they are Q - coordinates for Hamiltonian MCMC\n",
    "   \n",
    "   4) prior (alpha, beta) are two float variables describing beta-distribution classes' popabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.5.2\r\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.cm import rainbow\n",
    "import collections\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy.stats as sps\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf():\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        tf.reset_default_graph()\n",
    "        try:\n",
    "            sess.close()\n",
    "        except:\n",
    "            pass\n",
    "        sess = tf.InteractiveSession()\n",
    "        \n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_data():\n",
    "    ps_data_arr = np.array([\n",
    "        [20, 10, 1, 0.499993], [20, 3, 2, 0.230211], [20, 8, 3, 0.236831], \n",
    "        [20, 7, 4, 0.246463], [20, 6, 5, 0.370862], [20, 5, 6, 0.320656], \n",
    "        [20, 10, 7, 0.519887], [20, 12, 8, 0.52845], [20, 8, 9, 0.453077], \n",
    "        [20, 8, 10, 0.431245], [20, 10, 11, 0.499243], [20, 9, 12, 0.471968], \n",
    "        [20, 2, 13, 0.152176], [20, 14, 14, 0.48496], [20, 6, 15, 0.246193]\n",
    "    ])\n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    return ps_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(classes=15, alpha=1, beta=10, samples=20):\n",
    "    p = np.random.beta(alpha, beta, size=classes)\n",
    "    clicks = np.random.binomial(samples, p)\n",
    "    \n",
    "    ps_data_arr = np.array([\n",
    "        [samples, clicks[i], i + 1, p[i]] for i in range(classes)\n",
    "    ])\n",
    "    \n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    return ps_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_HMC_graph(ps_data_pd, sample_size, num_burnin_steps, num_steps_between_results, num_leapfrog_steps, adaptation_steps, step_size_initializer):\n",
    "    sess = reset_tf()\n",
    "\n",
    "    def _make_ps_prior(num_classes, alpha, beta, dtype):\n",
    "        return tfd.Independent(\n",
    "          tfd.Beta(\n",
    "              alpha * tf.ones(num_classes),\n",
    "              beta * tf.ones(num_classes)),\n",
    "              reinterpreted_batch_ndims=1)\n",
    "\n",
    "    def _make_ps_log_likelihood(prob, class_id, total_count):\n",
    "        prob_c = tf.gather(prob, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "        total_count_c = tf.gather(total_count, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "        return tfp.distributions.Binomial(total_count=tf.to_float(total_count_c), probs=prob_c)\n",
    "    \n",
    "    make_ps_prior = tf.make_template(name_='make_ps_prior', func_=_make_ps_prior)\n",
    "    make_ps_log_likelihood = tf.make_template(name_='make_ps_log_likelihood', func_=_make_ps_log_likelihood)\n",
    "    \n",
    "    def joint_log_prob(prob, alpha, beta, total_count, clicks, class_id, dtype):\n",
    "        num_classes = len(total_count)\n",
    "        rv_prob = make_ps_prior(num_classes, alpha, beta, dtype)\n",
    "        rv_clicks = make_ps_log_likelihood(prob, class_id, total_count)\n",
    "        return (rv_prob.log_prob(prob) + \n",
    "             tf.reduce_sum(rv_clicks.log_prob(clicks), axis=-1))\n",
    "    \n",
    "    dtype = np.float32\n",
    "    def unnormalized_posterior_log_prob(prob, log_alpha, log_beta):\n",
    "        return joint_log_prob(\n",
    "            prob=tf.sigmoid(prob),\n",
    "            alpha=tf.exp(log_alpha),\n",
    "            beta=tf.exp(log_beta),\n",
    "            total_count=dtype(ps_data_pd.total_count.values),\n",
    "            clicks=dtype(ps_data_pd.clicks.values),\n",
    "            class_id=np.int32(ps_data_pd.class_id.values),\n",
    "            dtype=dtype)\n",
    "\n",
    "    step_size = tf.get_variable(\n",
    "        'step_size',\n",
    "        initializer=step_size_initializer,\n",
    "        trainable=False)\n",
    "    \n",
    "    hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "        num_leapfrog_steps=num_leapfrog_steps,\n",
    "        step_size=step_size,\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(adaptation_steps)\n",
    "    )\n",
    "\n",
    "    parameters_num = len(ps_data_pd)\n",
    "    init_random_weights = tf.placeholder(dtype, shape=[parameters_num])\n",
    "    alpha_pl = tf.placeholder(dtype, shape=())\n",
    "    beta_pl = tf.placeholder(dtype, shape=())\n",
    "    \n",
    "    next_states, kernel_results = tfp.mcmc.sample_chain(\n",
    "        num_results=sample_size,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        num_steps_between_results=num_steps_between_results,\n",
    "        current_state=[init_random_weights, alpha_pl, beta_pl],\n",
    "        kernel=hmc)\n",
    "    \n",
    "    accepted_results = kernel_results.accepted_results\n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "    \n",
    "    init_op.run()\n",
    "    \n",
    "    return init_random_weights, alpha_pl, beta_pl, kernel_results, next_states, sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HMC_solution(train, val, L):\n",
    "    ps_data_arr = np.array([\n",
    "        [L, train[i] + val[i], i + 1, 0]\n",
    "        for i in range(train.shape[0])\n",
    "    ])\n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    sample_size = 5000\n",
    "    num_burnin_steps = 0\n",
    "    num_steps_between_results = 0\n",
    "    num_leapfrog_steps = 3\n",
    "    adaptation_steps = None\n",
    "    step_size_initializer = 0.01\n",
    "    init_random_weights, alpha_pl, beta_pl, kernel_results, next_states, sess = init_HMC_graph(\n",
    "        ps_data_pd, sample_size, num_burnin_steps, num_steps_between_results, num_leapfrog_steps, adaptation_steps, step_size_initializer)\n",
    "    \n",
    "    parameters_num = len(ps_data_pd)\n",
    "    dtype = np.float32\n",
    "    \n",
    "    w_ = 0.5 * np.ones([parameters_num], dtype=dtype)\n",
    "    alpha_ = .1\n",
    "    beta_ = .1\n",
    "    \n",
    "    p_prob = np.zeros_like(w_, dtype=np.float32)\n",
    "    \n",
    "    alphas = np.array([])\n",
    "    betas = np.array([])\n",
    "    \n",
    "    for i in tqdm(range(100)):\n",
    "\n",
    "        [\n",
    "          kernel_results_,\n",
    "          next_states_\n",
    "        ] = sess.run([\n",
    "          kernel_results,\n",
    "          next_states\n",
    "        ], feed_dict={init_random_weights: w_, alpha_pl: alpha_, beta_pl: beta_})\n",
    "\n",
    "        num_accepted = kernel_results_.is_accepted.sum()\n",
    "        num_drawn = kernel_results_.is_accepted.size\n",
    "        acceptance_rate = num_accepted / num_drawn\n",
    "        print (num_accepted, num_drawn, acceptance_rate)\n",
    "        for i in range(sample_size):\n",
    "            p_prob += bayesian_solve(next_states_[1][i], next_states_[2][i], train + val, 2 * L)\n",
    "        #p_prob += (1 / (1 + np.exp(-next_states_[0]))).mean(axis=0) какие то очень плохие результаты\n",
    "        w_ = next_states_[0][-1]\n",
    "        alpha_ = next_states_[1][-1]\n",
    "        beta_ = next_states_[2][-1]\n",
    "        \n",
    "        #alphas = np.append(alphas, next_states_[1])\n",
    "        #betas = np.append(betas, next_states_[2])\n",
    "    print (p_prob / 100 / sample_size)\n",
    "    return p_prob / 100 / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "data_set_small = load_data_set('./datasets/100.10')\n",
    "data_set_big = load_data_set('./datasets/100.100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02085861220032036"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic_solutions import *\n",
    "\n",
    "evaluate(stupid_solution, data_set_big.train_data[0], data_set_big.val_data[0], data_set_big.ideal[0], data_set_big.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce659120a69c41c48dc9827575c9828d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462 5000 0.4924\n",
      "3019 5000 0.6038\n",
      "3038 5000 0.6076\n",
      "3000 5000 0.6\n",
      "3048 5000 0.6096\n",
      "3001 5000 0.6002\n",
      "3014 5000 0.6028\n",
      "3006 5000 0.6012\n",
      "2950 5000 0.59\n",
      "3013 5000 0.6026\n",
      "3020 5000 0.604\n",
      "3045 5000 0.609\n",
      "3042 5000 0.6084\n",
      "3006 5000 0.6012\n",
      "3041 5000 0.6082\n",
      "3046 5000 0.6092\n",
      "3072 5000 0.6144\n",
      "2904 5000 0.5808\n",
      "2929 5000 0.5858\n",
      "2949 5000 0.5898\n",
      "2926 5000 0.5852\n",
      "2912 5000 0.5824\n",
      "2844 5000 0.5688\n",
      "2837 5000 0.5674\n",
      "3013 5000 0.6026\n",
      "2988 5000 0.5976\n",
      "2962 5000 0.5924\n",
      "2874 5000 0.5748\n",
      "2848 5000 0.5696\n",
      "2940 5000 0.588\n",
      "2964 5000 0.5928\n",
      "2876 5000 0.5752\n",
      "2899 5000 0.5798\n",
      "2893 5000 0.5786\n",
      "2909 5000 0.5818\n",
      "2858 5000 0.5716\n",
      "2865 5000 0.573\n",
      "2918 5000 0.5836\n",
      "2830 5000 0.566\n",
      "2948 5000 0.5896\n",
      "2981 5000 0.5962\n",
      "3039 5000 0.6078\n",
      "2997 5000 0.5994\n",
      "3034 5000 0.6068\n",
      "2973 5000 0.5946\n",
      "3027 5000 0.6054\n",
      "3013 5000 0.6026\n",
      "3029 5000 0.6058\n",
      "2992 5000 0.5984\n",
      "2927 5000 0.5854\n",
      "2991 5000 0.5982\n",
      "2968 5000 0.5936\n",
      "2993 5000 0.5986\n",
      "2957 5000 0.5914\n",
      "2964 5000 0.5928\n",
      "2947 5000 0.5894\n",
      "3005 5000 0.601\n",
      "2963 5000 0.5926\n",
      "3056 5000 0.6112\n",
      "2958 5000 0.5916\n",
      "2976 5000 0.5952\n",
      "2993 5000 0.5986\n",
      "2922 5000 0.5844\n",
      "3002 5000 0.6004\n",
      "2822 5000 0.5644\n",
      "2930 5000 0.586\n",
      "2951 5000 0.5902\n",
      "3017 5000 0.6034\n",
      "2919 5000 0.5838\n",
      "2913 5000 0.5826\n",
      "2893 5000 0.5786\n",
      "2943 5000 0.5886\n",
      "2919 5000 0.5838\n",
      "2855 5000 0.571\n",
      "2896 5000 0.5792\n",
      "2795 5000 0.559\n",
      "2844 5000 0.5688\n",
      "2913 5000 0.5826\n",
      "2959 5000 0.5918\n",
      "2923 5000 0.5846\n",
      "2935 5000 0.587\n",
      "2937 5000 0.5874\n",
      "2881 5000 0.5762\n",
      "2863 5000 0.5726\n",
      "2818 5000 0.5636\n",
      "2942 5000 0.5884\n",
      "2914 5000 0.5828\n",
      "2842 5000 0.5684\n",
      "2917 5000 0.5834\n",
      "2957 5000 0.5914\n",
      "2984 5000 0.5968\n",
      "2958 5000 0.5916\n",
      "2908 5000 0.5816\n",
      "2824 5000 0.5648\n",
      "2872 5000 0.5744\n",
      "2953 5000 0.5906\n",
      "2912 5000 0.5824\n",
      "2936 5000 0.5872\n",
      "2966 5000 0.5932\n",
      "2959 5000 0.5918\n",
      "\n",
      "[1.14478615e-04 1.29376887e-04 1.22153416e-01 1.04953309e-04\n",
      " 1.22153416e-01 4.12103534e-02 9.51215848e-02 1.29376887e-04\n",
      " 4.12103534e-02 1.04953309e-04 6.85021952e-02 2.32605696e-01\n",
      " 1.04953309e-04 1.42026814e-02 1.42026814e-02 1.04953309e-04\n",
      " 1.29376887e-04 1.42026814e-02 1.04953309e-04 1.14478615e-04\n",
      " 1.42026814e-02 1.42026814e-02 1.42026814e-02 1.04953309e-04\n",
      " 1.77402735e-01 1.04953309e-04 1.42026814e-02 2.03651235e-01\n",
      " 1.04953309e-04 1.14478615e-04 2.32605696e-01 1.29376887e-04\n",
      " 1.04953309e-04 1.29376887e-04 6.85021952e-02 1.42026814e-02\n",
      " 4.12103534e-02 4.12103534e-02 1.22153416e-01 1.14478615e-04\n",
      " 4.12103534e-02 1.42026814e-02 1.14478615e-04 1.29376887e-04\n",
      " 1.04953309e-04 1.04953309e-04 6.85021952e-02 1.14478615e-04\n",
      " 1.22153416e-01 9.51215848e-02 2.03651235e-01 1.49276793e-01\n",
      " 1.04953309e-04 1.29376887e-04 6.85021952e-02 4.12103534e-02\n",
      " 1.77402735e-01 4.12103534e-02 4.12103534e-02 2.57958293e-01\n",
      " 1.77402735e-01 2.57958293e-01 1.42026814e-02 1.04953309e-04\n",
      " 6.85021952e-02 1.14478615e-04 2.32605696e-01 1.04953309e-04\n",
      " 2.57958293e-01 1.04953309e-04 1.42026814e-02 1.04953309e-04\n",
      " 1.22153416e-01 1.04953309e-04 1.14478615e-04 1.04953309e-04\n",
      " 1.42026814e-02 2.03651235e-01 1.42026814e-02 6.85021952e-02\n",
      " 1.29376887e-04 1.04953309e-04 1.04953309e-04 6.85021952e-02\n",
      " 1.29376887e-04 4.12103534e-02 1.04953309e-04 1.04953309e-04\n",
      " 1.04953309e-04 1.29376887e-04 1.29376887e-04 1.14478615e-04\n",
      " 9.51215848e-02 1.29376887e-04 1.04953309e-04 1.29376887e-04\n",
      " 1.22153416e-01 1.04953309e-04 1.04953309e-04 1.04953309e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.06394917150604032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_id = 0\n",
    "\n",
    "\n",
    "evaluate(HMC_solution,\n",
    "         data_set_big.train_data[t_id],\n",
    "         data_set_big.val_data[t_id],\n",
    "         data_set_big.ideal[t_id],\n",
    "         data_set_big.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_alpha_and_beta(ps_data_pd, sample_size, num_burnin_steps, num_steps_between_results, num_leapfrog_steps, adaptation_steps):\n",
    "    init_random_weights, alpha_pl, beta_pl, kernel_results, next_states, sess = init_HMC_graph(ps_data_pd, sample_size, num_burnin_steps, num_steps_between_results, num_leapfrog_steps, adaptation_steps)\n",
    "    \n",
    "    parameters_num = len(ps_data_pd)\n",
    "    dtype = np.float32\n",
    "    \n",
    "    w_ = 0.5 * np.ones([parameters_num], dtype=dtype)\n",
    "    alpha_ = .1\n",
    "    beta_ = .1\n",
    "    \n",
    "    alphas = np.array([])\n",
    "    betas = np.array([])\n",
    "    \n",
    "    for i in tqdm(range(100)):\n",
    "\n",
    "        [\n",
    "          kernel_results_,\n",
    "          next_states_\n",
    "        ] = sess.run([\n",
    "          kernel_results,\n",
    "          next_states\n",
    "        ], feed_dict={init_random_weights: w_, alpha_pl: alpha_, beta_pl: beta_})\n",
    "\n",
    "        num_accepted = kernel_results_.is_accepted.sum()\n",
    "        num_drawn = kernel_results_.is_accepted.size\n",
    "        acceptance_rate = num_accepted / num_drawn\n",
    "        print (num_accepted, num_drawn, acceptance_rate)\n",
    "        w_ = next_states_[0][-1]\n",
    "        alpha_ = next_states_[1][-1]\n",
    "        beta_ = next_states_[2][-1]\n",
    "        \n",
    "        alphas = np.append(alphas, next_states_[1])\n",
    "        betas = np.append(betas, next_states_[2])\n",
    "    \n",
    "    return np.array([alphas, betas]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_count</th>\n",
       "      <th>clicks</th>\n",
       "      <th>class_id</th>\n",
       "      <th>true_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.515861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.425608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.541650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.471204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.503902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.479321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.480249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.422055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.514083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.507534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.489626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.515362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.492295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.526351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.518915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.476026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.591155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.504167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_count  clicks  class_id    true_p\n",
       "1.0          20.0    11.0         1  0.505107\n",
       "2.0          20.0    10.0         2  0.515861\n",
       "3.0          20.0     5.0         3  0.456393\n",
       "4.0          20.0     5.0         4  0.425608\n",
       "5.0          20.0    12.0         5  0.541650\n",
       "6.0          20.0     9.0         6  0.471204\n",
       "7.0          20.0     6.0         7  0.503902\n",
       "8.0          20.0     7.0         8  0.479321\n",
       "9.0          20.0     9.0         9  0.480249\n",
       "10.0         20.0     9.0        10  0.422055\n",
       "11.0         20.0     6.0        11  0.514083\n",
       "12.0         20.0     9.0        12  0.507534\n",
       "13.0         20.0     8.0        13  0.489626\n",
       "14.0         20.0    12.0        14  0.515362\n",
       "15.0         20.0    11.0        15  0.492295\n",
       "16.0         20.0    13.0        16  0.526351\n",
       "17.0         20.0     9.0        17  0.518915\n",
       "18.0         20.0    10.0        18  0.476026\n",
       "19.0         20.0    14.0        19  0.591155\n",
       "20.0         20.0     9.0        20  0.504167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 100\n",
    "beta = 100\n",
    "data = sample_data(classes=20, alpha=alpha, beta=beta)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "init_HMC_graph() missing 1 required positional argument: 'step_size_initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-67f76fa48ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_alpha_and_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-847ec6d83b79>\u001b[0m in \u001b[0;36msample_alpha_and_beta\u001b[0;34m(ps_data_pd, sample_size, num_burnin_steps, num_steps_between_results, num_leapfrog_steps, adaptation_steps)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_alpha_and_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps_data_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_burnin_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_between_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leapfrog_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaptation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minit_random_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_HMC_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps_data_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_burnin_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_between_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leapfrog_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madaptation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparameters_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps_data_pd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: init_HMC_graph() missing 1 required positional argument: 'step_size_initializer'"
     ]
    }
   ],
   "source": [
    "samples = sample_alpha_and_beta(data, int(1000 * 100), 0, 0, 10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(samples[:, 0], samples[:, 1], alpha=0.3)\n",
    "    plt.scatter(samples[:, 0], samples[:, 1], c=rainbow(np.linspace(0, 1, samples.shape[0])))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot((samples[:, 0] - samples[:, 0].mean()) / samples[:, 0].std())\n",
    "    plt.plot((samples[:, 1] - samples[:, 1].mean()) / samples[:, 1].std())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.exp(samples[:-80000:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "y = sps.beta(0.16, 0.38).pdf(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "with open('chain.pkl', 'wb') as output:\n",
    "    pickle.dump(chains, output, pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('chain.pkl', 'rb') as input_:\n",
    "    chains = pickle.load(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in chains:\n",
    "    print (len(ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = 10000\n",
    "for ch in chains:\n",
    "    if len(ch) > start:\n",
    "        print(len(ch))\n",
    "        samples = ch[start::300]\n",
    "        \n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(samples[:, 0], samples[:, 1], alpha=0.3)\n",
    "        plt.scatter(samples[:, 0], samples[:, 1], c=rainbow(np.linspace(0, 1, samples.shape[0])))\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot((samples[:, 0] - samples[:, 0].mean()) / samples[:, 0].std())\n",
    "        plt.plot((samples[:, 1] - samples[:, 1].mean()) / samples[:, 1].std())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, это уже похоже на распределение плотности. Значит разумный размер burnin -- 10^6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
