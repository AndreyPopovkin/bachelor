{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is model, where we should do binary classification - predict probability of A\n",
    "\n",
    "   1) num_classes - number of classes\n",
    "   \n",
    "   2) each class has its popability of A\n",
    "   \n",
    "   3) prob - array of these probabilities; they are Q - coordinates for Hamiltonian MCMC\n",
    "   \n",
    "   4) prior (alpha, beta) are two float variables describing beta-distribution classes' popabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_tf():\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        tf.reset_default_graph()\n",
    "        try:\n",
    "            sess.close()\n",
    "        except:\n",
    "            pass\n",
    "        sess = tf.InteractiveSession()\n",
    "        \n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_data():\n",
    "    ps_data_arr = np.array([\n",
    "        [20, 10, 1, 0.499993], [20, 3, 2, 0.230211], [20, 8, 3, 0.236831], \n",
    "        [20, 7, 4, 0.246463], [20, 6, 5, 0.370862], [20, 5, 6, 0.320656], \n",
    "        [20, 10, 7, 0.519887], [20, 12, 8, 0.52845], [20, 8, 9, 0.453077], \n",
    "        [20, 8, 10, 0.431245], [20, 10, 11, 0.499243], [20, 9, 12, 0.471968], \n",
    "        [20, 2, 13, 0.152176], [20, 14, 14, 0.48496], [20, 6, 15, 0.246193]\n",
    "    ])\n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    return ps_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(classes=15, alpha=1, beta=10, samples=20):\n",
    "    p = np.random.beta(alpha, beta, size=classes)\n",
    "    clicks = np.random.binomial(samples, p)\n",
    "    \n",
    "    ps_data_arr = np.array([\n",
    "        [samples, clicks[i], i + 1, p[i]] for i in range(classes)\n",
    "    ])\n",
    "    \n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    return ps_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_alpha_and_beta(ps_data_pd):\n",
    "    \n",
    "    sess = reset_tf()\n",
    "\n",
    "    inv_alpha_transform = lambda y: np.log(y)  # Not using TF here.\n",
    "    fwd_alpha_transform = tf.exp\n",
    "\n",
    "    def _make_ps_prior(num_classes, dtype):\n",
    "        raw_prior_alpha = tf.get_variable(\n",
    "          name='raw_prior_alpha',\n",
    "          initializer=np.array(inv_alpha_transform(5.), dtype=dtype))\n",
    "        raw_prior_beta = tf.get_variable(\n",
    "          name='raw_prior_beta',\n",
    "          initializer=np.array(inv_alpha_transform(5.), dtype=dtype))   \n",
    "        return tfd.Independent(\n",
    "          tfd.Beta(\n",
    "              fwd_alpha_transform(raw_prior_alpha) * tf.ones(num_classes),\n",
    "              fwd_alpha_transform(raw_prior_beta) * tf.ones(num_classes) * 10),\n",
    "          reinterpreted_batch_ndims=-1)#1)\n",
    "\n",
    "    def _make_ps_log_likelihood(prob, class_id, total_count):\n",
    "        prob_c = tf.gather(prob, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "        total_count_c = tf.gather(total_count, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "        return tfp.distributions.Binomial(total_count=tf.to_float(total_count_c), probs=prob_c)\n",
    "    \n",
    "    make_ps_prior = tf.make_template(name_='make_ps_prior', func_=_make_ps_prior)\n",
    "    make_ps_log_likelihood = tf.make_template(name_='make_ps_log_likelihood', func_=_make_ps_log_likelihood)\n",
    "    \n",
    "    def joint_log_prob(prob, total_count, clicks, class_id, dtype):\n",
    "        num_classes = len(total_count)\n",
    "        rv_prob = make_ps_prior(num_classes, dtype)\n",
    "        rv_clicks = make_ps_log_likelihood(prob, class_id, total_count)\n",
    "        return (rv_prob.log_prob(prob) + \n",
    "             tf.reduce_sum(rv_clicks.log_prob(clicks), axis=-1))\n",
    "    \n",
    "    dtype = np.float32\n",
    "    def unnormalized_posterior_log_prob(prob):\n",
    "        return joint_log_prob(\n",
    "            prob=tf.sigmoid(prob),\n",
    "            total_count=dtype(ps_data_pd.total_count.values),\n",
    "            clicks=dtype(ps_data_pd.clicks.values),\n",
    "            class_id=np.int32(ps_data_pd.class_id.values),\n",
    "            dtype=dtype)\n",
    "\n",
    "    step_size = tf.get_variable(\n",
    "        'step_size',\n",
    "        initializer=0.01,\n",
    "        trainable=False)\n",
    "\n",
    "    hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "        num_leapfrog_steps=10,\n",
    "        step_size=step_size,#0.01,\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(target_rate=0.75),\n",
    "        state_gradients_are_stopped=True)\n",
    "\n",
    "    init_random_weights = tf.placeholder(dtype, shape=[len(ps_data_pd)])\n",
    "\n",
    "    posterior_random_weights, kernel_results = tfp.mcmc.sample_chain(\n",
    "        num_results=3,\n",
    "        num_burnin_steps=0,\n",
    "        num_steps_between_results=0,\n",
    "        current_state=init_random_weights,\n",
    "        kernel=hmc)\n",
    "\n",
    "    loss = -tf.reduce_mean(kernel_results.accepted_results.target_log_prob)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        learning_rate=0.1,\n",
    "        global_step=global_step,\n",
    "        decay_steps=2,\n",
    "        decay_rate=0.9995)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    with tf.variable_scope('make_ps_prior', reuse=True):\n",
    "        prior_alpha = fwd_alpha_transform(tf.get_variable(\n",
    "            name='raw_prior_alpha', dtype=dtype))\n",
    "        prior_beta = fwd_alpha_transform(tf.get_variable(\n",
    "            name='raw_prior_beta', dtype=dtype))\n",
    "\n",
    "    init_op.run()\n",
    "    w_ = 0.5 * np.ones([len(ps_data_pd)], dtype=dtype)\n",
    "    \n",
    "    maxiter = int(3000)\n",
    "    num_accepted = 0\n",
    "    num_drawn = 0\n",
    "    alphas = []\n",
    "    betas = []\n",
    "    for i in range(maxiter):\n",
    "        [\n",
    "          _,\n",
    "          global_step_,\n",
    "          loss_,\n",
    "          posterior_random_weights_,\n",
    "          kernel_results_,\n",
    "          step_size_,\n",
    "          prior_alpha_,\n",
    "          prior_beta_,\n",
    "          #raw_prior_alpha_,\n",
    "          #raw_prior_beta_\n",
    "        ] = sess.run([\n",
    "          train_op,\n",
    "          global_step,\n",
    "          loss,\n",
    "          posterior_random_weights,\n",
    "          kernel_results,\n",
    "          step_size,\n",
    "          prior_alpha,\n",
    "          prior_beta,\n",
    "          #tf.get_variable(name='raw_prior_alpha'),\n",
    "          #tf.get_variable(name='raw_prior_beta')\n",
    "        ], feed_dict={init_random_weights: w_})\n",
    "        \n",
    "        w_ = posterior_random_weights_[-1, :]\n",
    "        num_accepted += kernel_results_.is_accepted.sum()\n",
    "        num_drawn += kernel_results_.is_accepted.size\n",
    "        acceptance_rate = num_accepted / num_drawn\n",
    "        if i > 500 or True:\n",
    "            alphas.append(prior_alpha_)\n",
    "            betas.append(prior_beta_)\n",
    "        \n",
    "        if i % 100 == 0 or i == maxiter - 1 or \\\n",
    "            loss_.mean() != loss_.mean() or \\\n",
    "            prior_alpha_ != prior_alpha_ or \\\n",
    "            prior_beta_ != prior_beta_ \\\n",
    "            : \n",
    "            clear_output()\n",
    "            print('global_step:{:>4}  loss:{: 7.1f}  acceptance:{:.3f}  '\n",
    "                  'step_size:{:.3f}  prior_alpha:{:.4f}  prior_beta:{:.4f}'.format(\n",
    "                      global_step_, loss_.mean(),\n",
    "                      acceptance_rate, step_size_,\n",
    "                      prior_alpha_, prior_beta_)\n",
    "            )\n",
    "            print (kernel_results_.proposed_state)\n",
    "            plt.plot(alphas)\n",
    "            plt.plot(np.array(betas) * 10)\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            if loss_.mean() != loss_.mean() or \\\n",
    "                prior_alpha_ != prior_alpha_ or \\\n",
    "                prior_beta_ != prior_beta_ \\\n",
    "                :\n",
    "                print (global_step_,\n",
    "                      loss_,\n",
    "                      posterior_random_weights_,\n",
    "                      kernel_results_,\n",
    "                      step_size_,\n",
    "                      prior_alpha_,\n",
    "                      prior_beta_,\n",
    "                      sep=\"\\n--------\\n\")\n",
    "                print (\"-\" * 50)\n",
    "                print (global_step___,\n",
    "                      loss___,\n",
    "                      posterior_random_weights___,\n",
    "                      kernel_results___,\n",
    "                      step_size___,\n",
    "                      prior_alpha___,\n",
    "                      prior_beta___,\n",
    "                      sep=\"\\n--------\\n\")\n",
    "                return None, None\n",
    "                \n",
    "        [\n",
    "          _,\n",
    "          global_step___,\n",
    "          loss___,\n",
    "          posterior_random_weights___,\n",
    "          kernel_results___,\n",
    "          step_size___,\n",
    "          prior_alpha___,\n",
    "          prior_beta___\n",
    "        ] = [\n",
    "          _,\n",
    "          global_step_,\n",
    "          loss_,\n",
    "          posterior_random_weights_,\n",
    "          kernel_results_,\n",
    "          step_size_,\n",
    "          prior_alpha_,\n",
    "          prior_beta_\n",
    "        ]\n",
    "    return prior_alpha_, prior_beta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 219  loss:    nan  acceptance:0.673  step_size:0.029  prior_alpha:nan  prior_beta:nan\n",
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n",
      "--------\n",
      "nan\n",
      "--------\n",
      "[[ -3.2583332  -16.29046     -0.26232782  -6.843421   -15.378631\n",
      "  -13.667314    -3.579461    -3.4989984  -14.338581    -7.8666797\n",
      "  -10.222091   -13.214819    -9.8136425   -0.8443723   -0.3600217 ]\n",
      " [ -3.2583332  -16.29046     -0.26232782  -6.843421   -15.378631\n",
      "  -13.667314    -3.579461    -3.4989984  -14.338581    -7.8666797\n",
      "  -10.222091   -13.214819    -9.8136425   -0.8443723   -0.3600217 ]\n",
      " [ -3.2583332  -16.29046     -0.26232782  -6.843421   -15.378631\n",
      "  -13.667314    -3.579461    -3.4989984  -14.338581    -7.8666797\n",
      "  -10.222091   -13.214819    -9.8136425   -0.8443723   -0.3600217 ]]\n",
      "--------\n",
      "MetropolisHastingsKernelResults(accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "      dtype=float32), target_log_prob=array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan]], dtype=float32), grads_target_log_prob=[array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan]], dtype=float32)]), is_accepted=array([[False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]]), log_accept_ratio=array([[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf]], dtype=float32), proposed_state=array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan]], dtype=float32), proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf],\n",
      "       [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
      "        -inf, -inf, -inf, -inf]], dtype=float32), target_log_prob=array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan]], dtype=float32), grads_target_log_prob=[array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan]], dtype=float32)]), extra=HamiltonianMonteCarloExtraKernelResults(step_size_assign=array([0.02899926, 0.02899926, 0.02899926], dtype=float32)))\n",
      "--------\n",
      "0.028999263\n",
      "--------\n",
      "nan\n",
      "--------\n",
      "nan\n",
      "--------------------------------------------------\n",
      "218\n",
      "--------\n",
      "4.8851714\n",
      "--------\n",
      "[[ -3.346984   -16.291142    -0.26232782  -7.1711636  -15.315047\n",
      "  -14.246423    -3.579461    -3.4989984  -14.340153    -7.5806775\n",
      "   -9.869452   -12.700317    -9.351947    -0.8443723   -0.3600217 ]\n",
      " [ -3.2583332  -16.29046     -0.26232782  -6.843421   -15.378631\n",
      "  -13.667314    -3.579461    -3.4989984  -14.338581    -7.8666797\n",
      "  -10.222091   -13.214819    -9.8136425   -0.8443723   -0.3600217 ]\n",
      " [ -3.2583332  -16.29046     -0.26232782  -6.843421   -15.378631\n",
      "  -13.667314    -3.579461    -3.4989984  -14.338581    -7.8666797\n",
      "  -10.222091   -13.214819    -9.8136425   -0.8443723   -0.3600217 ]]\n",
      "--------\n",
      "MetropolisHastingsKernelResults(accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([[ 6.9007957e-01, -3.3448756e-01,  0.0000000e+00, -1.8154660e-01,\n",
      "        -7.1066424e-02, -6.0282445e-01,  1.4368052e+00,  9.7981769e-01,\n",
      "         2.0200035e-02,  2.8286964e-01,  2.5705743e-01,  3.0018753e-01,\n",
      "        -2.3237550e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.0834773e-01,  5.5977050e-04,  0.0000000e+00,  3.5943595e-01,\n",
      "        -5.2339662e-02,  4.7681630e-01,  1.4368052e+00,  9.7981769e-01,\n",
      "         1.2929374e-03, -2.7361429e-01, -2.9488969e-01, -4.2385793e-01,\n",
      "        -3.8969052e-01,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.0834773e-01,  5.5977050e-04,  0.0000000e+00,  3.5943595e-01,\n",
      "        -5.2339662e-02,  4.7681630e-01,  1.4368052e+00,  9.7981769e-01,\n",
      "         1.2929374e-03, -2.7361429e-01, -2.9488969e-01, -4.2385793e-01,\n",
      "        -3.8969052e-01,  0.0000000e+00,  0.0000000e+00]], dtype=float32), target_log_prob=array([[-3.2122459e+00,  7.0132184e+00, -3.4147175e+01, -2.3740292e-02,\n",
      "         6.8631482e+00,  5.7571101e+00, -3.0123439e+00, -3.0813165e+00,\n",
      "         5.8780818e+00,  3.1369734e-01,  2.1981564e+00,  4.5283189e+00,\n",
      "         1.7721519e+00, -3.3410774e+01, -3.4016857e+01],\n",
      "       [-2.8675756e+00,  7.4346600e+00, -3.4147175e+01,  1.2769508e-01,\n",
      "         7.4346600e+00,  5.7872276e+00, -3.0123439e+00, -3.0813165e+00,\n",
      "         6.2982292e+00,  9.7070265e-01,  2.9098754e+00,  5.3732519e+00,\n",
      "         2.5736575e+00, -3.3410774e+01, -3.4016857e+01],\n",
      "       [-2.8675756e+00,  7.4346600e+00, -3.4147175e+01,  1.2769508e-01,\n",
      "         7.4346600e+00,  5.7872276e+00, -3.0123439e+00, -3.0813165e+00,\n",
      "         6.2982292e+00,  9.7070265e-01,  2.9098754e+00,  5.3732519e+00,\n",
      "         2.5736575e+00, -3.3410774e+01, -3.4016857e+01]], dtype=float32), grads_target_log_prob=[array([[   3.9376147 ,   -0.8231514 , -131.78581   ,   -1.0544001 ,\n",
      "          -0.82316035,   -0.8233128 ,    6.003943  ,    5.3392363 ,\n",
      "          -0.8232847 ,   -0.976709  ,   -0.8386875 ,   -0.8240252 ,\n",
      "          -0.84924793,  -91.37068   , -124.60583   ],\n",
      "       [   3.0235705 ,   -0.8231514 , -131.78581   ,   -1.1439606 ,\n",
      "          -0.8231514 ,   -0.82343864,    6.003943  ,    5.3392363 ,\n",
      "          -0.823285  ,   -0.93851686,   -0.83405745,   -0.8236556 ,\n",
      "          -0.83958167,  -91.37068   , -124.60583   ],\n",
      "       [   3.0235705 ,   -0.8231514 , -131.78581   ,   -1.1439606 ,\n",
      "          -0.8231514 ,   -0.82343864,    6.003943  ,    5.3392363 ,\n",
      "          -0.823285  ,   -0.93851686,   -0.83405745,   -0.8236556 ,\n",
      "          -0.83958167,  -91.37068   , -124.60583   ]], dtype=float32)]), is_accepted=array([[ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False, False],\n",
      "       [ True,  True, False,  True,  True,  True, False, False,  True,\n",
      "         True,  True,  True,  True, False, False],\n",
      "       [False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]]), log_accept_ratio=array([[ 2.8767263e+01,  2.6659767e+01, -1.3846933e+02,  2.7706060e+01,\n",
      "         2.7804276e+01,  2.7679581e+01,  2.9452559e+01,  2.8926233e+01,\n",
      "         2.7748466e+01,  2.7787640e+01,  2.7752565e+01,  2.7748741e+01,\n",
      "         2.7740311e+01, -7.0831024e+01, -1.2568375e+02],\n",
      "       [ 3.6322564e-02,  4.2200133e-01, -1.3884377e+02,  5.1087129e-01,\n",
      "         5.1917207e-01,  5.0693381e-01, -1.6304091e+00, -1.3066080e+00,\n",
      "         4.2144036e-01,  3.8339102e-01,  4.1682935e-01,  4.2107511e-01,\n",
      "         4.1181505e-01, -7.2096054e+01, -1.2496595e+02],\n",
      "       [          -inf,           -inf,           -inf,           -inf,\n",
      "                  -inf,           -inf,           -inf,           -inf,\n",
      "                  -inf,           -inf,           -inf,           -inf,\n",
      "                  -inf,           -inf,           -inf]], dtype=float32), proposed_state=array([[ -3.346984 , -16.291142 ,  -4.265822 ,  -7.1711636, -15.315047 ,\n",
      "        -14.246423 ,  -3.579461 ,  -3.4989984, -14.340153 ,  -7.5806775,\n",
      "         -9.869452 , -12.700317 ,  -9.351947 ,  -3.5791378,  -4.1606207],\n",
      "       [ -3.2583332, -16.29046  ,  -4.4740014,  -6.843421 , -15.378631 ,\n",
      "        -13.667314 ,  -3.1681716,  -3.083607 , -14.338581 ,  -7.8666797,\n",
      "        -10.222091 , -13.214819 ,  -9.8136425,  -3.809494 ,  -4.1021056],\n",
      "       [ -2.9457924,         nan,  -4.271514 ,  -6.783282 , -14.985211 ,\n",
      "        -14.147097 ,  -3.2965846,  -2.9545221, -14.30855  ,  -7.964262 ,\n",
      "        -10.344187 , -13.305114 , -10.296077 ,  -3.5218723,  -4.167153 ]],\n",
      "      dtype=float32), proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=array([[ 6.9007957e-01, -3.3448756e-01, -1.7018550e+02, -1.8154660e-01,\n",
      "        -7.1066424e-02, -6.0282445e-01,  1.4368052e+00,  9.7981769e-01,\n",
      "         2.0200035e-02,  2.8286964e-01,  2.5705743e-01,  3.0018753e-01,\n",
      "        -2.3237550e-01, -1.0122918e+02, -1.5718115e+02],\n",
      "       [-3.0834773e-01,  5.5977050e-04, -1.7115587e+02,  3.5943595e-01,\n",
      "        -5.2339662e-02,  4.7681630e-01, -1.6967524e+00, -1.3680222e+00,\n",
      "         1.2929374e-03, -2.7361429e-01, -2.9488969e-01, -4.2385793e-01,\n",
      "        -3.8969052e-01, -1.0311202e+02, -1.5683551e+02],\n",
      "       [-3.6506620e-01,           -inf, -1.7021468e+02,  6.9384530e-02,\n",
      "         3.2385480e-01, -3.9504135e-01, -1.3469695e+00, -1.3853843e+00,\n",
      "         2.4724327e-02, -9.1048434e-02, -1.0175670e-01, -7.4369989e-02,\n",
      "        -4.0340030e-01, -1.0069947e+02, -1.5721739e+02]], dtype=float32), target_log_prob=array([[-3.212246  ,  7.0132184 , -2.4310083 , -0.02374029,  6.863148  ,\n",
      "         5.75711   , -3.012344  , -3.0813165 ,  5.878082  ,  0.31369734,\n",
      "         2.1981564 ,  4.528319  ,  1.772152  , -3.0126214 , -2.519454  ],\n",
      "       [-2.8675756 ,  7.43466   , -1.8350663 ,  0.12769508,  7.43466   ,\n",
      "         5.7872276 , -2.9460006 , -3.0199022 ,  6.298229  ,  0.97070265,\n",
      "         2.9098754 ,  5.373252  ,  2.5736575 , -2.3948069 , -2.1472945 ],\n",
      "       [        nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan,\n",
      "                nan,         nan,         nan,         nan,         nan]],\n",
      "      dtype=float32), grads_target_log_prob=[array([[ 3.9376147 , -0.8231514 , -4.993609  , -1.0544001 , -0.82316035,\n",
      "        -0.8233128 ,  6.003943  ,  5.3392363 , -0.8232847 , -0.976709  ,\n",
      "        -0.8386875 , -0.8240252 , -0.84924793, -8.998638  , -5.449154  ],\n",
      "       [ 3.0235705 , -0.8231514 , -4.2186503 , -1.1439606 , -0.8231514 ,\n",
      "        -0.82343864,  2.0137453 ,  0.9874407 , -0.823285  , -0.93851686,\n",
      "        -0.83405745, -0.8236556 , -0.83958167, -7.3529944 , -5.723389  ],\n",
      "       [-0.86414814,         nan, -4.970259  , -1.1638441 , -0.8231783 ,\n",
      "        -0.8233309 ,  3.4272263 , -0.7398925 , -0.8232904 , -0.92779046,\n",
      "        -0.83279884, -0.8236082 , -0.83327645, -9.466655  , -5.419494  ]],\n",
      "      dtype=float32)]), extra=HamiltonianMonteCarloExtraKernelResults(step_size_assign=array([0.02987797, 0.02987797, 0.02987797], dtype=float32)))\n",
      "--------\n",
      "0.029877972\n",
      "--------\n",
      "0.17689355\n",
      "--------\n",
      "0.3031121\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    alpha = 1 + np.random.randint(10)\n",
    "    beta = 10 + np.random.randint(100)\n",
    "    a, b = approximate_alpha_and_beta(sample_data(alpha=alpha, beta=beta))\n",
    "    if a is None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
