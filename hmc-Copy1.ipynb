{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aapopovkin/venv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(11, 9)\n",
    "\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy snippet to reset the global graph and global session.\n",
    "with warnings.catch_warnings():\n",
    "  warnings.simplefilter('ignore')\n",
    "  tf.reset_default_graph()\n",
    "  try:\n",
    "    sess.close()\n",
    "  except:\n",
    "    pass\n",
    "  sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is model, where we should do binary classification - predict probability of A\n",
    "\n",
    "   1) num_classes - number of classes\n",
    "   \n",
    "   2) each class has its popability of A\n",
    "   \n",
    "   3) prob - array of these probabilities; they are Q - coordinates for Hamiltonian MCMC\n",
    "   \n",
    "   4) prior (alpha, beta) are two float variables describing beta-distribution classes' popabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data():\n",
    "    ps_data_arr = np.array([\n",
    "        [20, 10, 1, 0.499993], [20, 3, 2, 0.230211], [20, 8, 3, 0.236831], \n",
    "        [20, 7, 4, 0.246463], [20, 6, 5, 0.370862], [20, 5, 6, 0.320656], \n",
    "        [20, 10, 7, 0.519887], [20, 12, 8, 0.52845], [20, 8, 9, 0.453077], \n",
    "        [20, 8, 10, 0.431245], [20, 10, 11, 0.499243], [20, 9, 12, 0.471968], \n",
    "        [20, 2, 13, 0.152176], [20, 14, 14, 0.48496], [20, 6, 15, 0.246193]\n",
    "    ])\n",
    "    ps_data_pd=pd.DataFrame(data=ps_data_arr[0:, 0:],\n",
    "             index=ps_data_arr[0:, 2],\n",
    "             columns=[\"total_count\", \"clicks\", \"class_id\", \"true_p\"],\n",
    "             dtype=np.float32)\n",
    "    ps_data_pd['class_id'] = ps_data_pd.class_id.astype('int32')\n",
    "    \n",
    "    return ps_data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_alpha_transform = lambda y: np.log(y)  # Not using TF here.\n",
    "fwd_alpha_transform = tf.exp\n",
    "\n",
    "def _make_ps_prior(num_classes, dtype):\n",
    "    raw_prior_alpha = tf.get_variable(\n",
    "      name='raw_prior_alpha',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))\n",
    "    raw_prior_beta = tf.get_variable(\n",
    "      name='raw_prior_beta',\n",
    "      initializer=np.array(inv_alpha_transform(5.), dtype=dtype))   \n",
    "    return tfd.Independent(\n",
    "      tfd.Beta(\n",
    "          fwd_alpha_transform(raw_prior_alpha) * tf.ones(num_classes),\n",
    "          fwd_alpha_transform(raw_prior_beta) * tf.ones(num_classes)),\n",
    "      reinterpreted_batch_ndims=1)\n",
    "\n",
    "make_ps_prior = tf.make_template(name_='make_ps_prior', func_=_make_ps_prior)\n",
    "\n",
    "def _make_ps_log_likelihood(prob, class_id, total_count):\n",
    "    prob_c = tf.gather(prob, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "    total_count_c = tf.gather(total_count, indices=tf.to_int32(class_id - 1), axis=-1)\n",
    "    return tfp.distributions.Binomial(total_count=tf.to_float(total_count_c), probs=prob_c)\n",
    "\n",
    "make_ps_log_likelihood = tf.make_template(name_='make_ps_log_likelihood', func_=_make_ps_log_likelihood)\n",
    "\n",
    "def joint_log_prob(prob, total_count, clicks, class_id, dtype):\n",
    "    num_classes = len(total_count)\n",
    "    rv_prob = make_ps_prior(num_classes, dtype)\n",
    "    rv_clicks = make_ps_log_likelihood(prob, class_id, total_count)\n",
    "    return (rv_prob.log_prob(prob) + \n",
    "         tf.reduce_sum(rv_clicks.log_prob(clicks), axis=-1))\n",
    "\n",
    "\n",
    "def approximate_alpha_and_beta(ps_data_pd):\n",
    "    \n",
    "    dtype = np.float32\n",
    "    def unnormalized_posterior_log_prob(prob):\n",
    "        return joint_log_prob(\n",
    "            prob=prob,\n",
    "            total_count=dtype(ps_data_pd.total_count.values),\n",
    "            clicks=dtype(ps_data_pd.clicks.values),\n",
    "            class_id=np.int32(ps_data_pd.class_id.values),\n",
    "            dtype=dtype)\n",
    "\n",
    "    step_size = tf.get_variable(\n",
    "        'step_size',\n",
    "        initializer=0.001,\n",
    "        trainable=False)\n",
    "\n",
    "    hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "        num_leapfrog_steps=1000,\n",
    "        step_size=step_size,#0.01,\n",
    "        step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(target_rate=0.99),\n",
    "        state_gradients_are_stopped=True)\n",
    "\n",
    "    init_random_weights = tf.placeholder(dtype, shape=[len(ps_data_pd)])\n",
    "\n",
    "    posterior_random_weights, kernel_results = tfp.mcmc.sample_chain(\n",
    "        num_results=3,\n",
    "        num_burnin_steps=0,\n",
    "        num_steps_between_results=0,\n",
    "        current_state=init_random_weights,\n",
    "        kernel=hmc)\n",
    "\n",
    "    loss = -tf.reduce_mean(kernel_results.accepted_results.target_log_prob)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        learning_rate=0.1,\n",
    "        global_step=global_step,\n",
    "        decay_steps=2,\n",
    "        decay_rate=0.998)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    with tf.variable_scope('make_ps_prior', reuse=True):\n",
    "        prior_alpha = fwd_alpha_transform(tf.get_variable(\n",
    "            name='raw_prior_alpha', dtype=dtype))\n",
    "        prior_beta = fwd_alpha_transform(tf.get_variable(\n",
    "            name='raw_prior_beta', dtype=dtype))\n",
    "\n",
    "    init_op.run()\n",
    "    w_ = 0.5 * np.ones([len(ps_data_pd)], dtype=dtype)\n",
    "    \n",
    "    \n",
    "    maxiter = int(3000)\n",
    "    num_accepted = 0\n",
    "    num_drawn = 0\n",
    "    for i in range(maxiter):\n",
    "        [\n",
    "          _,\n",
    "          global_step_,\n",
    "          loss_,\n",
    "          posterior_random_weights_,\n",
    "          kernel_results_,\n",
    "          step_size_,\n",
    "          prior_alpha_,\n",
    "          prior_beta_\n",
    "        ] = sess.run([\n",
    "          train_op,\n",
    "          global_step,\n",
    "          loss,\n",
    "          posterior_random_weights,\n",
    "          kernel_results,\n",
    "          step_size,\n",
    "          prior_alpha,\n",
    "          prior_beta\n",
    "        ], feed_dict={init_random_weights: w_})\n",
    "        \n",
    "        w_ = posterior_random_weights_[-1, :]\n",
    "        num_accepted += kernel_results_.is_accepted.sum()\n",
    "        num_drawn += kernel_results_.is_accepted.size\n",
    "        acceptance_rate = num_accepted / num_drawn\n",
    "        if i % 1 == 0 or i == maxiter - 1:\n",
    "            print('global_step:{:>4}  loss:{: 7.1f}  acceptance:{:.3f}  '\n",
    "                  'step_size:{:.3f}  prior_alpha:{:.4f}  prior_beta:{:.4f}'.format(\n",
    "                      global_step_, loss_.mean(),\n",
    "                      acceptance_rate, step_size_,\n",
    "                      prior_alpha_, prior_beta_)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19066147859922178"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (1 + np.exp(2.2))\n",
    "196 / (832 + 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_alpha:55.1133  prior_beta:747.7076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aapopovkin/venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-b4e51b394b3a>:20: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-b4e51b394b3a>:22: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float32\n",
    "\n",
    "ps_data_pd = get_sample_data()\n",
    "\n",
    "def unnormalized_posterior_log_prob(prob):\n",
    "    return joint_log_prob(\n",
    "        prob=prob,\n",
    "        total_count=dtype(ps_data_pd.total_count.values),\n",
    "        clicks=dtype(ps_data_pd.clicks.values),\n",
    "        class_id=np.int32(ps_data_pd.class_id.values),\n",
    "        dtype=dtype)\n",
    "\n",
    "step_size = tf.get_variable(\n",
    "    'step_size',\n",
    "    initializer=0.001,\n",
    "    trainable=False)\n",
    "\n",
    "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "    num_leapfrog_steps=1,\n",
    "    step_size=step_size,#0.01,\n",
    "    step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(target_rate=0.99),\n",
    "    state_gradients_are_stopped=True)\n",
    "\n",
    "initial_state  = tf.placeholder(dtype, shape=[len(ps_data_pd)])\n",
    "\n",
    "bootstrap_results = hmc.bootstrap_results(initial_state)\n",
    "\n",
    "step = hmc.one_step(initial_state, bootstrap_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = (np.random.normal(loc=0.5, scale=0.2, size=len(ps_data_pd)))\n",
    "st[st < 0] = 0.001\n",
    "st[st > 1] = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetropolisHastingsKernelResults(accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=0.0, target_log_prob=-151.1382, grads_target_log_prob=[array([ 1.6157387e+01,  1.1412880e+02, -4.3469543e+01, -7.8273230e+00,\n",
       "       -1.7525230e+01, -4.0278740e+01, -6.5233183e+00,  1.5987987e+04,\n",
       "       -9.2642231e+00, -2.4163134e+01,  6.1668488e+01,  3.2638706e+01,\n",
       "       -1.1561338e+01, -1.1413849e+01, -4.1079098e+01], dtype=float32)]), is_accepted=False, log_accept_ratio=-inf, proposed_state=array([ 1.5936775e+00,  6.5293989e+00, -1.9338468e+00,  2.7264917e-01,\n",
       "       -8.5312968e-01, -1.5800996e+00,  4.7973242e-01,  9.2431696e+02,\n",
       "       -1.4110649e-01, -9.7305721e-01,  3.2833693e+00,  2.5210164e+00,\n",
       "       -5.6428713e-01, -3.5238785e-01, -1.7056563e+00], dtype=float32), proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(log_acceptance_correction=-inf, target_log_prob=nan, grads_target_log_prob=[array([      nan,       nan,       nan, 16.972395,       nan,       nan,\n",
       "        2.273705,       nan,       nan,       nan,       nan,       nan,\n",
       "             nan,       nan,       nan], dtype=float32)]), extra=HamiltonianMonteCarloExtraKernelResults(step_size_assign=0.33663365))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer().run()\n",
    "sess.run(step_size.assign(0.34))\n",
    "res = sess.run([bootstrap_results, step], feed_dict={initial_state: st})[1][1]\n",
    "res#.accepted_results.grads_target_log_prob, res.proposed_results.grads_target_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.8840, 10.6375\n",
    "\n",
    "# 7.2159, 10.9869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = res.accepted_results.grads_target_log_prob[0], res.proposed_results.grads_target_log_prob[0], res.proposed_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16.972395  2.273705       nan       nan       nan]\n",
      "[ -7.827323   -6.5233183  -9.264223  -11.561338  -11.413849 ]\n",
      "[ 0.27264917  0.47973242 -0.14110649 -0.5642871  -0.35238785]\n"
     ]
    }
   ],
   "source": [
    "print (b[np.abs(a) < 15])\n",
    "print (a[np.abs(a) < 15])\n",
    "print (c[np.abs(a) < 15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
